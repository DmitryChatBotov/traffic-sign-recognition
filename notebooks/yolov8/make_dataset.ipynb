{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0141a838-67b7-4f16-8c57-76a9447eaa48",
   "metadata": {},
   "source": [
    "В данном ноутбуке происходит загрузка датасета из kaggle и его конвертация в YOLO формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781807c6-33f8-4e3f-8160-2038f8d2855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from shutil import copy, rmtree\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d385db4a-3e41-4a5f-87f5-5721a5265b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"<введите имя пользователя>\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"<введите ключ>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003fb28b-e232-4d89-991f-ce4bd5f62d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle import api\n",
    "\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226c53d-f19b-4739-976f-5226c5c18f38",
   "metadata": {},
   "source": [
    "## Скачивание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae396b5f-aaa2-40fe-abf2-339b790bcf73",
   "metadata": {},
   "source": [
    "Авторизовываемся в kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021fe8bf-18fe-4a8e-92df-074d74c85b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_id: str, output_dataset_path: Path | str) -> None:\n",
    "    \"\"\"Скачивает датасет из kaggle по id.\"\"\"\n",
    "    api.dataset_download_files(\n",
    "        dataset_id, path=output_dataset_path, unzip=True, quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90bec8-c455-4cd1-a928-a2c60432a076",
   "metadata": {},
   "source": [
    "Скачиваем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef711a2d-01f4-4efb-91d4-87ab2af51e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading rtsd-dataset.zip to data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.1G/17.1G [38:57<00:00, 7.87MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_dataset(dataset_id=\"watchman/rtsd-dataset\", output_dataset_path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a0394",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497fa195",
   "metadata": {},
   "outputs": [],
   "source": [
    "##тут точно будут картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c068fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d577b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"train_anno.json\") as file:\n",
    "    train_anno = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37313a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"val_anno.json\") as file:\n",
    "    val_anno = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aed938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {item[\"id\"]: item[\"name\"] for item in train_anno[\"categories\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5328572",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count_by_category = Counter(\n",
    "    [class_names[item[\"category_id\"]] for item in train_anno[\"annotations\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ce8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_categories_count = {\n",
    "    cat_name: cat_count\n",
    "    for cat_name, cat_count in samples_count_by_category.items()\n",
    "    if cat_count < 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13e8692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7_15': 16,\n",
       " '8_8': 19,\n",
       " '8_3_3': 2,\n",
       " '2_3_6': 10,\n",
       " '5_18': 17,\n",
       " '2_3_5': 1,\n",
       " '8_1_3': 22,\n",
       " '1_31': 16,\n",
       " '5_4': 14,\n",
       " '6_8_2': 13,\n",
       " '2_3_4': 12,\n",
       " '4_8_3': 13,\n",
       " '1_7': 13,\n",
       " '1_18': 18,\n",
       " '2_7': 7,\n",
       " '4_5': 2,\n",
       " '8_18': 23,\n",
       " '8_4_4': 21,\n",
       " '6_15_3': 4,\n",
       " '5_12': 8,\n",
       " '3_16': 12,\n",
       " '1_30': 11,\n",
       " '1_6': 16,\n",
       " '8_6_2': 23,\n",
       " '6_8_3': 12,\n",
       " '3_33': 1,\n",
       " '8_4_3': 5,\n",
       " '8_14': 4,\n",
       " '8_17': 16,\n",
       " '3_6': 11,\n",
       " '1_26': 12,\n",
       " '6_8_1': 4,\n",
       " '5_17': 9,\n",
       " '1_10': 18,\n",
       " '8_16': 3,\n",
       " '7_18': 5,\n",
       " '7_14': 7,\n",
       " '8_23': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_categories_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c5e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_mapping = {cls_name: cls_id for (cls_id, cls_name) in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5056acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_categories = {\n",
    "    cat_name: categories_mapping[cat_name]\n",
    "    for cat_name in invalid_categories_count.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43053768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7_15': 11,\n",
       " '8_8': 37,\n",
       " '8_3_3': 59,\n",
       " '2_3_6': 73,\n",
       " '5_18': 75,\n",
       " '2_3_5': 76,\n",
       " '8_1_3': 84,\n",
       " '1_31': 90,\n",
       " '5_4': 96,\n",
       " '6_8_2': 98,\n",
       " '2_3_4': 105,\n",
       " '4_8_3': 106,\n",
       " '1_7': 111,\n",
       " '1_18': 113,\n",
       " '2_7': 114,\n",
       " '4_5': 123,\n",
       " '8_18': 125,\n",
       " '8_4_4': 126,\n",
       " '6_15_3': 132,\n",
       " '5_12': 133,\n",
       " '3_16': 134,\n",
       " '1_30': 135,\n",
       " '1_6': 137,\n",
       " '8_6_2': 138,\n",
       " '6_8_3': 139,\n",
       " '3_33': 141,\n",
       " '8_4_3': 142,\n",
       " '8_14': 144,\n",
       " '8_17': 145,\n",
       " '3_6': 146,\n",
       " '1_26': 147,\n",
       " '6_8_1': 149,\n",
       " '5_17': 150,\n",
       " '1_10': 151,\n",
       " '8_16': 152,\n",
       " '7_18': 153,\n",
       " '7_14': 154,\n",
       " '8_23': 155}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b4b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_invalid_categories(annotation, invalid_categories: dict[str, int]):\n",
    "    annotation = deepcopy(annotation)\n",
    "    valid_annotations = [\n",
    "        ann\n",
    "        for ann in annotation[\"annotations\"]\n",
    "        if ann[\"category_id\"] not in invalid_categories.values()\n",
    "    ]\n",
    "    valid_categories = [\n",
    "        cat\n",
    "        for cat in annotation[\"categories\"]\n",
    "        if cat[\"id\"] not in invalid_categories.values()\n",
    "    ]\n",
    "    valid_image_ids = set(ann[\"image_id\"] for ann in valid_annotations)\n",
    "    valid_images = [img for img in annotation[\"images\"] if img[\"id\"] in valid_image_ids]\n",
    "    val_annotation = {\n",
    "        \"annotations\": valid_annotations,\n",
    "        \"categories\": valid_categories,\n",
    "        \"images\": valid_images,\n",
    "    }\n",
    "    return val_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c313c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_category_ids(annotation):\n",
    "    # Create a mapping from original category IDs to new consecutive IDs\n",
    "    category_id_mapping = {\n",
    "        original_id: new_id\n",
    "        for new_id, original_id in enumerate(\n",
    "            set(cat[\"id\"] for cat in annotation[\"categories\"])\n",
    "        )\n",
    "    }\n",
    "    annotation = deepcopy(annotation)\n",
    "    # Remap category IDs in annotations\n",
    "    remapped_annotations = []\n",
    "    for idx in range(len(annotation[\"annotations\"])):\n",
    "        remapped_ann = annotation[\"annotations\"][idx]\n",
    "        remapped_ann[\"category_id\"] = category_id_mapping[remapped_ann[\"category_id\"]]\n",
    "        remapped_annotations.append(remapped_ann)\n",
    "\n",
    "    # Remap category IDs in categories\n",
    "    remapped_categories = []\n",
    "    for idx in range(len(annotation[\"categories\"])):\n",
    "        remapped_cat = annotation[\"categories\"][idx]\n",
    "        remapped_cat[\"id\"] = category_id_mapping[remapped_cat[\"id\"]]\n",
    "        remapped_categories.append(remapped_cat)\n",
    "\n",
    "    remapped_annotation = {\n",
    "        \"annotations\": remapped_annotations,\n",
    "        \"categories\": remapped_categories,\n",
    "        \"images\": annotation[\"images\"],\n",
    "    }\n",
    "\n",
    "    return remapped_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf560d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"train_annotation.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        remap_category_ids(filter_invalid_categories(train_anno, invalid_categories)), f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be83e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"val_annotation.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        remap_category_ids(filter_invalid_categories(val_anno, invalid_categories)), f\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de752ee",
   "metadata": {},
   "source": [
    "Уберем невалидные лейблы из labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4f92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"labels.txt\") as file:\n",
    "    labels = file.read().splitlines()\n",
    "\n",
    "labels = [label for label in labels if label not in invalid_categories.keys()]\n",
    "\n",
    "with open(dataset_path / \"valid_labels.txt\", \"w\") as file:\n",
    "    for label in labels:\n",
    "        file.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf80c8",
   "metadata": {},
   "source": [
    "## Конвертация в YOLO формат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef917d7e",
   "metadata": {},
   "source": [
    "Так как датасет в формате COCO, необходимо его конвертировать в YOLO формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a5fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset_path = Path(\"output_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d270fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dataset_path.exists():\n",
    "    rmtree(output_dataset_path)\n",
    "output_dataset_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040acdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_json(annotation_path: Path | str, output_dir: Path | str) -> None:\n",
    "    \"\"\"Конвертирует датасет в формате COCO в формат YOLO.\"\"\"\n",
    "    yolo_annotation_path: Path = Path(output_dir) / annotation_path.stem / \"labels\"\n",
    "    yolo_annotation_path.mkdir(parents=True)\n",
    "    with open(annotation_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = {\"%g\" % x[\"id\"]: x for x in data[\"images\"]}\n",
    "    img_to_annotaitons = defaultdict(list)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        img_to_annotaitons[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    # Write labels file\n",
    "    for img_id, anns in tqdm(\n",
    "        img_to_annotaitons.items(), desc=f\"Annotations {annotation_path}\"\n",
    "    ):\n",
    "        img = images[\"%g\" % img_id]\n",
    "        h, w, filename = img[\"height\"], img[\"width\"], img[\"file_name\"].split(\"/\")[1]\n",
    "\n",
    "        bboxes = []\n",
    "        for ann in anns:\n",
    "            if ann[\"iscrowd\"]:\n",
    "                continue\n",
    "            box = np.array(ann[\"bbox\"], dtype=np.float64)\n",
    "            box[:2] += box[2:] / 2\n",
    "            box[[0, 2]] /= w\n",
    "            box[[1, 3]] /= h\n",
    "            if box[2] <= 0 or box[3] <= 0:\n",
    "                continue\n",
    "\n",
    "            cls = ann[\"category_id\"] - 1\n",
    "            box = [cls] + box.tolist()\n",
    "            if box not in bboxes:\n",
    "                bboxes.append(box)\n",
    "\n",
    "        # Write\n",
    "        with open(\n",
    "            (yolo_annotation_path / Path(filename).name).with_suffix(\".txt\"), \"a\"\n",
    "        ) as file:\n",
    "            for i in range(len(bboxes)):\n",
    "                line = (*(bboxes[i]),)\n",
    "                file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29bb7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations data/train_annotation.json: 100%|██████████| 54099/54099 [00:03<00:00, 13541.43it/s]\n",
      "Annotations data/val_annotation.json: 100%|██████████| 4993/4993 [00:00<00:00, 13834.41it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_coco_json(dataset_path / \"train_annotation.json\", output_dataset_path)\n",
    "convert_coco_json(dataset_path / \"val_annotation.json\", output_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebac8c",
   "metadata": {},
   "source": [
    "Добавим изображения в датасет YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "069d5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [\n",
    "    filename.stem\n",
    "    for filename in (output_dataset_path / \"train_annotation/labels\").iterdir()\n",
    "]\n",
    "val_labels = [\n",
    "    filename.stem\n",
    "    for filename in (output_dataset_path / \"val_annotation/labels\").iterdir()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cabb8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_path = output_dataset_path / \"val_annotation/images\"\n",
    "val_images_path.mkdir(parents=True, exist_ok=True)\n",
    "train_images_path = output_dataset_path / \"train_annotation/images\"\n",
    "train_images_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abbe6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image copy...: 179138it [03:49, 781.59it/s] \n"
     ]
    }
   ],
   "source": [
    "images_path = dataset_path / \"rtsd-frames/rtsd-frames\"\n",
    "for filename in tqdm(images_path.iterdir(), desc=f\"Image copy...\"):\n",
    "    if filename.stem in train_labels:\n",
    "        copy(filename, train_images_path / filename.name)\n",
    "    if filename.stem in val_labels:\n",
    "        copy(filename, val_images_path / filename.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12434cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290dd7d",
   "metadata": {},
   "source": [
    "Создадим файл traffic-sign.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c18ec2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"valid_labels.txt\") as file:\n",
    "    labels = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b55356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dataset_path / \"traffic-sign.yaml\", \"w\") as file:\n",
    "    file.write(f\"train: {'/tf' / train_images_path}\\n\")\n",
    "    file.write(f\"val: {'/tf' / val_images_path}\\n\")\n",
    "    file.write(f\"nc: {len(labels)}\\n\")\n",
    "    file.write(f\"names: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8999a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: /tf/output_data/train_annotation/images\r\n",
      "val: /tf/output_data/val_annotation/images\r\n",
      "nc: 117\r\n",
      "names: ['2_1', '1_23', '1_17', '3_24', '8_2_1', '5_20', '5_19_1', '5_16', '3_25', '6_16', '2_2', '2_4', '8_13_1', '4_2_1', '1_20_3', '1_25', '3_4', '8_3_2', '3_4_1', '4_1_6', '4_2_3', '4_1_1', '1_33', '5_15_5', '3_27', '1_15', '4_1_2_1', '6_3_1', '8_1_1', '6_7', '5_15_3', '7_3', '1_19', '6_4', '8_1_4', '1_16', '1_11_1', '6_6', '5_15_1', '7_2', '5_15_2', '7_12', '3_18', '5_6', '5_5', '7_4', '4_1_2', '8_2_2', '7_11', '1_22', '1_27', '2_3_2', '5_15_2_2', '1_8', '3_13', '2_3', '2_3_3', '7_7', '1_11', '8_13', '1_12_2', '1_20', '1_12', '3_32', '2_5', '3_1', '4_8_2', '3_20', '3_2', '5_22', '7_5', '8_4_1', '3_14', '1_2', '1_20_2', '4_1_4', '7_6', '8_3_1', '4_3', '4_1_5', '8_2_3', '8_2_4', '3_10', '4_2_2', '7_1', '3_28', '4_1_3', '5_3', '3_31', '6_2', '1_21', '3_21', '1_13', '1_14', '6_15_2', '2_6', '3_18_2', '4_1_2_2', '3_19', '8_5_4', '5_15_7', '5_14', '5_21', '1_1', '6_15_1', '8_6_4', '8_15', '3_11', '3_30', '5_7_1', '5_7_2', '1_5', '3_29', '5_11', '3_12', '5_8', '8_5_2']"
     ]
    }
   ],
   "source": [
    "!cat output_data/traffic-sign.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
